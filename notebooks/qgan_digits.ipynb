{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import perceval as pcvl\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import RandomSampler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys; sys.path.insert(0, '..')\n",
    "from models.qgan import QGAN\n",
    "from helpers.data.digits import DigitsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions and constants\n",
    "image_size = 8\n",
    "batch_size = 4\n",
    "lossy = False\n",
    "write_to_disk=True\n",
    "\n",
    "# optimization params\n",
    "spsa_iter_num = 16000\n",
    "opt_iter_num = 2000\n",
    "lrD = 0.002\n",
    "opt_params={\"spsa_iter_num\": spsa_iter_num, \"opt_iter_num\": opt_iter_num, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define desired run configurations\n",
    "config = {\n",
    "    \"noise_dim\": 1,\n",
    "    \"arch\": [\"var\", \"var\", \"enc[2]\", \"var\", \"var\"],\n",
    "    \"input_state\": [0, 1, 0, 1, 0],\n",
    "    \"gen_count\": 4,\n",
    "    \"pnr\": False,\n",
    "}\n",
    "runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"./digits\"):\n",
    "    shutil.rmtree(\"./digits\")\n",
    "\n",
    "for digit in range(1, 10):\n",
    "    dataset = DigitsDataset(csv_file=\"../helpers/data/optdigits_csv.csv\", label=digit, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "    sampler = RandomSampler(dataset, replacement=True, num_samples=batch_size * opt_iter_num)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, drop_last=True, sampler=sampler\n",
    "    )\n",
    "    config_path = \"./digits/config_\" + str(digit)\n",
    "    if os.path.isdir(config_path):\n",
    "        continue\n",
    "    os.makedirs(config_path)\n",
    "\n",
    "    with open(os.path.join(config_path, \"config.json\"), \"w\") as f:\n",
    "        config.update({\"digit\": 1})\n",
    "        f.write(json.dumps(config))\n",
    "\n",
    "    gen_arch = config[\"arch\"]\n",
    "    noise_dim = config[\"noise_dim\"]\n",
    "    input_state = config[\"input_state\"]\n",
    "    pnr = config[\"pnr\"]\n",
    "    gen_count = config[\"gen_count\"]\n",
    "\n",
    "    run_num = 0\n",
    "    # several runs to average over\n",
    "    for i in tqdm(range(1000), desc=\"run\", position=1, leave=False):\n",
    "        if run_num == runs:\n",
    "            break\n",
    "        run_num += 1\n",
    "\n",
    "        save_path = config_path + \"/run_\" + str(run_num)\n",
    "        os.makedirs(save_path)\n",
    "        try:\n",
    "            qgan = QGAN(\n",
    "                image_size,\n",
    "                gen_count,\n",
    "                gen_arch,\n",
    "                pcvl.BasicState(input_state),\n",
    "                noise_dim,\n",
    "                batch_size,\n",
    "                pnr,\n",
    "                lossy\n",
    "            )\n",
    "            (\n",
    "                D_loss_progress,\n",
    "                G_loss_progress,\n",
    "                G_params_progress,\n",
    "                fake_data_progress,\n",
    "            ) = qgan.fit(\n",
    "                tqdm(dataloader, desc=\"iter\", position=2, leave=False),\n",
    "                lrD,\n",
    "                opt_params,\n",
    "                silent=True,\n",
    "            )\n",
    "\n",
    "            if write_to_disk:\n",
    "                np.savetxt(\n",
    "                    os.path.join(save_path, \"fake_progress.csv\"),\n",
    "                    fake_data_progress,\n",
    "                    delimiter=\",\",\n",
    "                )\n",
    "                np.savetxt(\n",
    "                    os.path.join(save_path, \"loss_progress.csv\"),\n",
    "                    np.array(np.array([D_loss_progress, G_loss_progress]).transpose()),\n",
    "                    delimiter=\",\",\n",
    "                    header=\"D_loss, G_loss\",\n",
    "                )\n",
    "                np.savetxt(\n",
    "                    os.path.join(save_path, \"G_params_progress.csv\"),\n",
    "                    np.array(G_params_progress),\n",
    "                    delimiter=\",\",\n",
    "                )\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(exc)\n",
    "            shutil.rmtree(save_path)\n",
    "            run_num -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
